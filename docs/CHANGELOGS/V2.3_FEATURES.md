# RhinoWAF v2.3 — Performance & Observability Release

**Release Date**: October 30, 2025  
**Focus**: Production monitoring and zero-downtime configuration updates

---

## Overview

v2.3 introduces comprehensive observability through Prometheus metrics and enables live configuration updates without service interruption. This release is designed for production deployments requiring real-time monitoring, alerting, and operational flexibility.

### Key Features

1. **Prometheus Metrics Endpoint** - 20+ metrics for comprehensive WAF monitoring
2. **Hot-Reload Configuration** - Update IP rules and GeoIP database without restart
3. **HTTP Reload API** - Programmatic configuration updates via REST endpoint
4. **SIGHUP Signal Handler** - Unix-style manual reload for DevOps workflows
5. **Configuration Validation** - Safe JSON validation with automatic rollback
6. **Debounced File Watching** - Intelligent file monitoring prevents reload storms

---

## Feature 1: Prometheus Metrics

### Overview

RhinoWAF v2.3 exposes comprehensive metrics at `/metrics` endpoint in Prometheus format, enabling integration with modern monitoring stacks (Prometheus, Grafana, AlertManager).

### Metrics Endpoint

```bash
# Access metrics
curl http://localhost:8080/metrics

# Sample output
# HELP rhinowaf_requests_total Total number of requests processed
# TYPE rhinowaf_requests_total counter
rhinowaf_requests_total{status="allowed"} 1543
rhinowaf_requests_total{status="blocked"} 87

# HELP rhinowaf_request_duration_seconds Request processing time
# TYPE rhinowaf_request_duration_seconds histogram
rhinowaf_request_duration_seconds_bucket{le="0.005"} 1234
rhinowaf_request_duration_seconds_bucket{le="0.01"} 1456
rhinowaf_request_duration_seconds_bucket{le="0.025"} 1520
```

### Available Metrics

#### Request Metrics

| Metric | Type | Labels | Description |
|--------|------|--------|-------------|
| `rhinowaf_requests_total` | Counter | `status` (allowed/blocked) | Total requests processed |
| `rhinowaf_requests_blocked` | Counter | `reason` (rate_limit, ip_rule, malicious_input, geo_block, etc.) | Blocked requests by reason |
| `rhinowaf_requests_allowed` | Counter | - | Successfully allowed requests |
| `rhinowaf_request_duration_seconds` | Histogram | - | Request processing latency |

**Example Queries:**

```promql
# Total request rate
rate(rhinowaf_requests_total[5m])

# Block rate by reason
rate(rhinowaf_requests_blocked[5m]) by (reason)

# Request success rate
rate(rhinowaf_requests_total{status="allowed"}[5m]) / rate(rhinowaf_requests_total[5m])

# 95th percentile latency
histogram_quantile(0.95, rate(rhinowaf_request_duration_seconds_bucket[5m]))

# 99th percentile latency
histogram_quantile(0.99, rate(rhinowaf_request_duration_seconds_bucket[5m]))
```

#### Challenge Metrics

| Metric | Type | Labels | Description |
|--------|------|--------|-------------|
| `rhinowaf_challenges_issued` | Counter | - | Total challenges issued to clients |
| `rhinowaf_challenges_passed` | Counter | - | Successfully completed challenges |
| `rhinowaf_challenges_failed` | Counter | - | Failed challenge attempts |
| `rhinowaf_challenge_sessions` | Gauge | - | Active challenge sessions |

**Example Queries:**

```promql
# Challenge pass rate
rate(rhinowaf_challenges_passed[5m]) / rate(rhinowaf_challenges_issued[5m])

# Challenge failure rate
rate(rhinowaf_challenges_failed[5m])

# Active challenge sessions
rhinowaf_challenge_sessions

# Challenge effectiveness (blocks prevented)
rate(rhinowaf_challenges_issued[5m]) - rate(rhinowaf_challenges_passed[5m])
```

#### Fingerprint Metrics

| Metric | Type | Labels | Description |
|--------|------|--------|-------------|
| `rhinowaf_fingerprints_collected` | Counter | - | Total fingerprints collected |
| `rhinowaf_fingerprints_blocked` | Counter | `reason` (missing_client_data, expired, bot_network, etc.) | Blocked fingerprints by reason |
| `rhinowaf_fingerprint_rate_limited` | Counter | - | Rate limited fingerprint collection requests |
| `rhinowaf_active_fingerprints` | Gauge | - | Currently tracked fingerprints |
| `rhinowaf_suspicious_fingerprints` | Gauge | - | Fingerprints flagged as suspicious |

**Example Queries:**

```promql
# Fingerprint collection rate
rate(rhinowaf_fingerprints_collected[5m])

# Bot network detection rate
rate(rhinowaf_fingerprints_blocked{reason="bot_network"}[5m])

# Suspicious fingerprint ratio
rhinowaf_suspicious_fingerprints / rhinowaf_active_fingerprints

# Fingerprint blocking effectiveness
rate(rhinowaf_fingerprints_blocked[5m]) by (reason)
```

#### Configuration Metrics

| Metric | Type | Labels | Description |
|--------|------|--------|-------------|
| `rhinowaf_config_reloads` | Counter | `config_type` (ip_rules, geoip) | Configuration reload count |

**Example Queries:**

```promql
# Reload frequency
rate(rhinowaf_config_reloads[1h]) by (config_type)

# Total reloads in last 24h
increase(rhinowaf_config_reloads[24h]) by (config_type)
```

### Grafana Dashboard

#### Quick Setup

1. **Install Prometheus** (if not already installed):

```bash
# Download Prometheus
wget https://github.com/prometheus/prometheus/releases/download/v2.47.0/prometheus-2.47.0.linux-amd64.tar.gz
tar xvf prometheus-2.47.0.linux-amd64.tar.gz
cd prometheus-2.47.0.linux-amd64

# Configure scraping
cat > prometheus.yml <<EOF
global:
  scrape_interval: 15s
  evaluation_interval: 15s

scrape_configs:
  - job_name: 'rhinowaf'
    static_configs:
      - targets: ['localhost:8080']
    metrics_path: '/metrics'
EOF

# Start Prometheus
./prometheus --config.file=prometheus.yml
```

2. **Create Grafana Dashboard**:

Import the following JSON dashboard or create panels manually:

```json
{
  "dashboard": {
    "title": "RhinoWAF v2.3 Monitoring",
    "panels": [
      {
        "title": "Request Rate",
        "targets": [
          {
            "expr": "rate(rhinowaf_requests_total[5m])"
          }
        ]
      },
      {
        "title": "Block Rate by Reason",
        "targets": [
          {
            "expr": "rate(rhinowaf_requests_blocked[5m]) by (reason)"
          }
        ]
      },
      {
        "title": "Request Latency (p95/p99)",
        "targets": [
          {
            "expr": "histogram_quantile(0.95, rate(rhinowaf_request_duration_seconds_bucket[5m]))",
            "legendFormat": "p95"
          },
          {
            "expr": "histogram_quantile(0.99, rate(rhinowaf_request_duration_seconds_bucket[5m]))",
            "legendFormat": "p99"
          }
        ]
      },
      {
        "title": "Challenge Effectiveness",
        "targets": [
          {
            "expr": "rate(rhinowaf_challenges_passed[5m]) / rate(rhinowaf_challenges_issued[5m])",
            "legendFormat": "Pass Rate"
          }
        ]
      }
    ]
  }
}
```

#### Sample Dashboard Panels

**Panel 1: Request Overview**
```promql
# Total request rate
rate(rhinowaf_requests_total[5m])

# Allowed vs Blocked
rate(rhinowaf_requests_total{status="allowed"}[5m])
rate(rhinowaf_requests_total{status="blocked"}[5m])
```

**Panel 2: Attack Detection**
```promql
# Top attack types
topk(5, rate(rhinowaf_requests_blocked[5m]) by (reason))

# Geo blocking effectiveness
rate(rhinowaf_requests_blocked{reason="geo_block"}[5m])
```

**Panel 3: Performance**
```promql
# Median latency
histogram_quantile(0.5, rate(rhinowaf_request_duration_seconds_bucket[5m]))

# 95th percentile
histogram_quantile(0.95, rate(rhinowaf_request_duration_seconds_bucket[5m]))

# Max latency
histogram_quantile(1.0, rate(rhinowaf_request_duration_seconds_bucket[5m]))
```

**Panel 4: Bot Detection**
```promql
# Bot network detection
rate(rhinowaf_fingerprints_blocked{reason="bot_network"}[5m])

# Fingerprint tracking
rhinowaf_active_fingerprints
rhinowaf_suspicious_fingerprints
```

### Alerting Rules

Create alerts in Prometheus or AlertManager:

```yaml
# prometheus_rules.yml
groups:
  - name: rhinowaf_alerts
    interval: 30s
    rules:
      # High block rate (potential attack)
      - alert: HighBlockRate
        expr: rate(rhinowaf_requests_blocked[5m]) > 10
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: "High request block rate detected"
          description: "RhinoWAF is blocking {{ $value }} requests/sec"

      # Very high block rate (active attack)
      - alert: ActiveAttack
        expr: rate(rhinowaf_requests_blocked[5m]) > 50
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "Active attack detected"
          description: "RhinoWAF is blocking {{ $value }} requests/sec - possible DDoS"

      # High latency
      - alert: HighLatency
        expr: histogram_quantile(0.95, rate(rhinowaf_request_duration_seconds_bucket[5m])) > 0.1
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High request latency"
          description: "95th percentile latency is {{ $value }}s"

      # Low challenge pass rate (possible bot attack)
      - alert: LowChallengePassRate
        expr: rate(rhinowaf_challenges_passed[5m]) / rate(rhinowaf_challenges_issued[5m]) < 0.3
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Low challenge pass rate"
          description: "Only {{ $value | humanizePercentage }} of challenges are passing"

      # Bot network detected
      - alert: BotNetworkDetected
        expr: rate(rhinowaf_fingerprints_blocked{reason="bot_network"}[5m]) > 1
        for: 2m
        labels:
          severity: critical
        annotations:
          summary: "Bot network detected"
          description: "Detecting {{ $value }} bot network fingerprints/sec"
```

### Integration with Monitoring Stack

#### Prometheus

```yaml
# Add to prometheus.yml
scrape_configs:
  - job_name: 'rhinowaf'
    static_configs:
      - targets: ['rhinowaf-server:8080']
    metrics_path: '/metrics'
    scrape_interval: 15s
```

#### Grafana Cloud

```bash
# Use remote_write to send to Grafana Cloud
# Add to prometheus.yml
remote_write:
  - url: https://prometheus-prod-01-eu-west-0.grafana.net/api/prom/push
    basic_auth:
      username: <your-username>
      password: <your-api-key>
```

#### Datadog

```yaml
# Use OpenMetrics integration in datadog.yaml
instances:
  - prometheus_url: http://localhost:8080/metrics
    namespace: "rhinowaf"
    metrics:
      - rhinowaf_*
```

---

## Feature 2: Hot-Reload Configuration

### Overview

Hot-reload enables live configuration updates without restarting RhinoWAF, ensuring zero downtime for production systems. Changes to IP rules and GeoIP database are validated and applied atomically.

### Auto-Watch File Monitoring

By default, RhinoWAF watches configuration files for changes:

```go
// Enabled by default in cmd/rhinowaf/main.go
reloadMgr, err := reload.NewManager(reload.Config{
    IPRulesPath:  "./config/ip_rules.json",
    GeoDBPath:    "./config/geoip.json",
    DebounceTime: 2 * time.Second,
    WatchEnabled: true,  // Auto-watch enabled
})
```

**How It Works:**

1. File system monitoring via `fsnotify` library
2. Detects changes to `config/ip_rules.json` and `config/geoip.json`
3. 2-second debounce window prevents reload storms during batch edits
4. Automatic JSON validation before applying changes
5. Atomic configuration swap - old config remains active if validation fails

**Example:**

```bash
# Edit config file
vim config/ip_rules.json
# Save changes

# Logs automatically show (after 2-second debounce):
# 2025/10/24 12:34:56 ✓ Detected change in config file: config/ip_rules.json
# 2025/10/24 12:34:56 ✓ Successfully reloaded IP rules
```

### Manual Reload via HTTP Endpoint

Trigger reload programmatically using REST API:

```bash
# Reload all configurations
curl -X POST http://localhost:8080/reload

# Success response:
{
  "status": "success",
  "config": {
    "ip_rules_path": "./config/ip_rules.json",
    "geodb_path": "./config/geoip.json",
    "debounce_time": "2s",
    "last_reloads": {
      "ip_rules": "2025-10-24T20:06:32Z",
      "geoip": "2025-10-24T20:06:32Z"
    }
  }
}

# Error response (invalid JSON):
{
  "status": "error",
  "error": "Invalid JSON in config/ip_rules.json: unexpected end of JSON input"
}
```

**Use Cases:**

- CI/CD pipeline integration (deploy config changes automatically)
- Configuration management systems (Ansible, Puppet, Chef)
- GitOps workflows (trigger reload after git pull)
- API-driven configuration updates

**Example CI/CD Integration:**

```yaml
# .github/workflows/deploy-config.yml
name: Deploy WAF Config
on:
  push:
    paths:
      - 'config/**'
jobs:
  deploy:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - name: Copy configs to server
        run: scp config/*.json server:/opt/rhinowaf/config/
      - name: Trigger reload
        run: curl -X POST http://server:8080/reload
      - name: Verify reload
        run: |
          response=$(curl -X POST http://server:8080/reload)
          if echo "$response" | jq -e '.status == "success"' > /dev/null; then
            echo "✓ Configuration reload successful"
          else
            echo "✗ Configuration reload failed"
            exit 1
          fi
```

### Manual Reload via SIGHUP Signal

Unix-style reload for DevOps workflows:

```bash
# Find RhinoWAF process ID
ps aux | grep rhinowaf
# Or use pidof
pidof rhinowaf

# Send SIGHUP signal
kill -SIGHUP <pid>

# Or use pkill
pkill -SIGHUP rhinowaf
```

**Logs will show:**

```
2025/10/24 12:35:00 Received SIGHUP, reloading configurations...
2025/10/24 12:35:00 Manually reloading IP rules...
2025/10/24 12:35:00 ✓ Successfully reloaded IP rules
2025/10/24 12:35:00 Manually reloading GeoIP database...
2025/10/24 12:35:00 ✓ Successfully reloaded GeoIP database
2025/10/24 12:35:00 ✓ All configurations reloaded successfully
```

**Use Cases:**

- Server management scripts
- Systemd integration (systemctl reload rhinowaf)
- Emergency config updates without HTTP access
- Traditional Unix admin workflows

### Configuration Validation

All reload methods include automatic validation:

#### IP Rules Validation

```bash
# Valid structure required
{
  "version": "2.0",
  "last_modified": "2025-10-24T00:00:00Z",
  "banned_ips": [...],
  "whitelisted_ips": [...],
  "geo_rules": [...],
  "global_rules": {...}
}
```

**Validation Checks:**

- ✓ Valid JSON syntax
- ✓ Required fields present (`version`, `global_rules`)
- ✓ IP addresses in correct format
- ✓ Country codes are valid (2-letter ISO)
- ✓ Numeric values in valid ranges

**If validation fails:**

```
2025/10/24 12:36:00 ✗ Failed to reload IP rules: invalid JSON syntax at line 45
2025/10/24 12:36:00 ✗ Previous configuration remains active
```

#### GeoIP Database Validation

```bash
# Accepts both array and object formats
[
  {
    "cidr": "1.0.0.0/8",
    "country": "US",
    "region": "North America"
  }
]

# Or object format
{
  "entries": [...]
}
```

**Validation Checks:**

- ✓ Valid JSON syntax
- ✓ CIDR notation correctness
- ✓ No overlapping ranges (warning only)

### Safe Reload Behavior

**Atomic Configuration Swap:**

1. Read new configuration file
2. Validate JSON structure
3. Parse and validate all rules
4. **ONLY IF ALL CHECKS PASS**: Replace active configuration
5. If any check fails: Log error, keep previous configuration

**Zero Downtime:**

- Requests continue processing during reload
- No connection drops or service interruption
- Gradual transition - new requests use new config, in-flight requests complete with old config

**Debounce Protection:**

- 2-second window prevents reload storms
- Multiple file changes within 2 seconds → single reload
- Useful for batch config updates (multiple file saves)

### Monitoring Reloads

Track reload events via Prometheus:

```promql
# Total reloads in last hour
increase(rhinowaf_config_reloads[1h]) by (config_type)

# Reload frequency
rate(rhinowaf_config_reloads[5m]) by (config_type)
```

Check reload status via logs:

```bash
# Watch for reload events
tail -f /var/log/rhinowaf.log | grep -i reload

# Count recent reloads
grep "Successfully reloaded" /var/log/rhinowaf.log | tail -20
```

### Best Practices

**1. Test Changes Before Deployment**

```bash
# Validate JSON syntax
jq '.' config/ip_rules.json > /dev/null && echo "✓ Valid JSON"

# Test on staging environment first
scp config/ip_rules.json staging:/opt/rhinowaf/config/
curl -X POST http://staging:8080/reload
```

**2. Version Control Configuration**

```bash
# Track all changes in git
cd /opt/rhinowaf/config
git add ip_rules.json geoip.json
git commit -m "Block malicious IPs: 203.0.113.0/24"
git push origin main

# Rollback if needed
git revert HEAD
kill -SIGHUP $(pidof rhinowaf)
```

**3. Automate Reload Verification**

```bash
#!/bin/bash
# reload_and_verify.sh

# Backup current config
cp config/ip_rules.json config/ip_rules.json.bak

# Deploy new config
cp /tmp/new_rules.json config/ip_rules.json

# Trigger reload
response=$(curl -s -X POST http://localhost:8080/reload)

# Check if successful
if echo "$response" | jq -e '.status == "success"' > /dev/null; then
    echo "✓ Reload successful"
    rm config/ip_rules.json.bak
else
    echo "✗ Reload failed, rolling back"
    mv config/ip_rules.json.bak config/ip_rules.json
    curl -s -X POST http://localhost:8080/reload
    exit 1
fi
```

**4. Monitor Reload Failures**

```yaml
# Prometheus alert for reload failures
- alert: ConfigReloadFailed
  expr: increase(rhinowaf_config_reload_errors[5m]) > 0
  labels:
    severity: warning
  annotations:
    summary: "Configuration reload failed"
    description: "Check RhinoWAF logs for validation errors"
```

---

## Upgrade Guide

### From v2.2 to v2.3

**No Breaking Changes** - v2.3 is fully backward compatible.

#### Step 1: Update Binary

```bash
# Stop current version
systemctl stop rhinowaf

# Backup current binary
cp /usr/local/bin/rhinowaf /usr/local/bin/rhinowaf.v2.2.bak

# Install v2.3
go build -o /usr/local/bin/rhinowaf ./cmd/rhinowaf

# Start new version
systemctl start rhinowaf
```

#### Step 2: Verify Metrics Endpoint

```bash
# Check metrics are exposed
curl http://localhost:8080/metrics | grep rhinowaf_requests_total

# Expected output:
# rhinowaf_requests_total{status="allowed"} 0
# rhinowaf_requests_total{status="blocked"} 0
```

#### Step 3: Test Hot-Reload

```bash
# Test HTTP endpoint
curl -X POST http://localhost:8080/reload

# Test SIGHUP
kill -SIGHUP $(pidof rhinowaf)

# Verify auto-watch in logs
tail -f /var/log/rhinowaf.log | grep "Watching"
# Expected: "✓ Watching IP rules: ./config/ip_rules.json"
```

#### Step 4: Configure Monitoring (Optional)

```bash
# Add Prometheus scraping
cat >> /etc/prometheus/prometheus.yml <<EOF
  - job_name: 'rhinowaf'
    static_configs:
      - targets: ['localhost:8080']
    metrics_path: '/metrics'
EOF

systemctl reload prometheus
```

---

## Configuration Reference

### Reload Manager Configuration

```go
// cmd/rhinowaf/main.go
reloadMgr, err := reload.NewManager(reload.Config{
    // Path to IP rules configuration
    IPRulesPath: "./config/ip_rules.json",
    
    // Path to GeoIP database
    GeoDBPath: "./config/geoip.json",
    
    // Debounce time - wait this long after file change before reloading
    // Prevents reload storms during batch edits
    DebounceTime: 2 * time.Second,
    
    // Enable automatic file watching
    // Set to false to disable auto-reload (manual reload only)
    WatchEnabled: true,
})
```

### Disable Auto-Watch

To disable automatic file watching (manual reload only):

```go
// cmd/rhinowaf/main.go
reloadMgr, err := reload.NewManager(reload.Config{
    IPRulesPath:  "./config/ip_rules.json",
    GeoDBPath:    "./config/geoip.json",
    DebounceTime: 2 * time.Second,
    WatchEnabled: false,  // Disable auto-watch
})
```

With auto-watch disabled:
- File changes are NOT automatically detected
- Use HTTP endpoint (`POST /reload`) or SIGHUP for manual reload
- Lower resource usage (no file system monitoring)

---

## Performance Impact

### Metrics Collection

- **CPU**: < 1% overhead (promauto registration, atomic counters)
- **Memory**: ~2MB (metric storage, histogram buckets)
- **Latency**: < 100μs per request (counter increments)

**No performance degradation** - metrics use lock-free atomic operations.

### Hot-Reload

- **File Watching**: < 0.1% CPU (fsnotify kernel events)
- **Reload Time**: 50-200ms depending on config size
- **Memory**: No additional overhead (reuses existing structures)
- **Request Processing**: No interruption during reload

**Zero downtime** - requests continue processing during configuration updates.

---

## Troubleshooting

### Metrics Not Appearing

```bash
# Check endpoint accessibility
curl http://localhost:8080/metrics

# If connection refused:
# 1. Verify RhinoWAF is running: ps aux | grep rhinowaf
# 2. Check port binding: netstat -tlnp | grep 8080
# 3. Review firewall rules: iptables -L

# If 404 error:
# 1. Verify v2.3 binary is running (check banner at startup)
# 2. Check for typos in URL (must be /metrics not /metric)
```

### Reload Not Working

```bash
# Test reload manually
curl -X POST http://localhost:8080/reload

# If error response:
# 1. Check JSON syntax: jq '.' config/ip_rules.json
# 2. Review logs for validation errors: tail -f /var/log/rhinowaf.log
# 3. Verify file permissions: ls -la config/

# If no response:
# 1. Check reload manager is initialized (startup logs)
# 2. Verify WatchEnabled: true in main.go
```

### Auto-Watch Not Detecting Changes

```bash
# Check startup logs for watch confirmation
grep "Watching" /var/log/rhinowaf.log
# Expected: "✓ Watching IP rules: ./config/ip_rules.json"

# If not watching:
# 1. Verify WatchEnabled: true in reload manager config
# 2. Check file system events: inotifywait -m config/
# 3. Ensure fsnotify is installed: go list -m github.com/fsnotify/fsnotify
```

### High Reload Frequency

```bash
# Check reload frequency
grep "Successfully reloaded" /var/log/rhinowaf.log | tail -50

# If reloading too frequently:
# 1. Increase DebounceTime: 5 * time.Second
# 2. Check for automated scripts modifying configs
# 3. Review file system events: inotifywait -m config/
```

---

## Security Considerations

### Metrics Endpoint

**Public Exposure:**

- `/metrics` endpoint is **NOT protected by WAF**
- Exposes operational data (request counts, block rates)
- **Recommendation**: Restrict access via firewall or reverse proxy

```nginx
# nginx configuration - restrict metrics access
location /metrics {
    allow 10.0.0.0/8;      # Internal network
    allow 192.168.0.0/16;  # Private network
    deny all;
    proxy_pass http://localhost:8080;
}
```

### Reload Endpoint

**Security:**

- `/reload` endpoint is **NOT authenticated**
- Can trigger configuration reloads (but validation prevents damage)
- **Recommendation**: Restrict access via firewall or add authentication

```bash
# iptables - allow reload only from localhost
iptables -A INPUT -p tcp --dport 8080 -s 127.0.0.1 -j ACCEPT
iptables -A INPUT -p tcp --dport 8080 -j DROP
```

### Configuration File Security

```bash
# Restrict config file permissions
chmod 600 config/ip_rules.json config/geoip.json
chown rhinowaf:rhinowaf config/*.json

# Prevent unauthorized modifications
chattr +i config/ip_rules.json  # Make immutable (root only can modify)
```

---

## Future Enhancements (v2.4+)

Planned improvements for hot-reload and metrics:

- **Partial Reload**: Reload only changed sections (IP rules vs geo rules)
- **Reload History**: Track last 100 reload events with diffs
- **Metrics Retention**: Configurable metric retention (default: 15 days)
- **Custom Metric Labels**: User-defined labels for request tagging
- **Reload Webhooks**: POST notifications on successful/failed reloads
- **Rollback API**: Automatic rollback to last known-good configuration
- **Configuration Diff**: Show what changed between reloads

---

## Support

For issues, questions, or feature requests:

- **GitHub Issues**: https://github.com/1rhino2/RhinoWAF/issues
- **Documentation**: https://github.com/1rhino2/RhinoWAF/tree/main/docs
- **Email**: support@rhinowaf.io

---

**Version**: 2.3  
**Release Date**: October 24, 2025  
**Next Release**: v3.0 (Q2 2026) - Enterprise Features
